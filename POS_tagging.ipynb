{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS tagging.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vkb2JFmPwCkY",
        "outputId": "87273b63-e53f-49d9-9800-ee192a1d832f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "stop_words=set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dWPT9e5wHwO",
        "outputId": "a9344480-8db4-411d-9756-78bb38f0df1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUYpOJZuwKuN",
        "outputId": "13633e30-cc27-4bac-b035-b231832d1567"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='my nation is india'"
      ],
      "metadata": {
        "id": "nVtXKAIQwNKb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized=sent_tokenize(text)\n",
        "\n",
        "for i in tokenized:\n",
        "    word_list=nltk.word_tokenize(i)\n",
        "    word_list =[w for w in word_list if not w in stop_words]\n",
        "    tagged=nltk.pos_tag(word_list)\n",
        "    print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPItrQv9wQXr",
        "outputId": "f784c016-2dbf-49ff-8689-e59c7f236c31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('nation', 'NN'), ('india', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing loading the library\n",
        "import spacy\n",
        "# python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "#POS-TAGGING\n",
        "# Process whole documents\n",
        "text = (\"\"\"My name is Sharadha. I love to work on data science problems. Please check out my github profile!\"\"\")\n",
        "doc = nlp(text)\n",
        "# Token and Tag\n",
        "for token in doc:\n",
        "  print(token, token.pos_)\n",
        "# You want list of Verb tokens\n",
        "print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZGulB72wUhW",
        "outputId": "945eed96-195a-45f8-e83c-c13eea56e9ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My DET\n",
            "name NOUN\n",
            "is AUX\n",
            "Sharadha PROPN\n",
            ". PUNCT\n",
            "I PRON\n",
            "love VERB\n",
            "to PART\n",
            "work VERB\n",
            "on ADP\n",
            "data NOUN\n",
            "science NOUN\n",
            "problems NOUN\n",
            ". PUNCT\n",
            "Please INTJ\n",
            "check VERB\n",
            "out ADP\n",
            "my DET\n",
            "github PROPN\n",
            "profile NOUN\n",
            "! PUNCT\n",
            "Verbs: ['love', 'work', 'check']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4UOEjB-weNU",
        "outputId": "d7090e81-df71-4349-b3b6-bdcb92122341"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
            "is be AUX VBZ aux xx True True\n",
            "looking look VERB VBG ROOT xxxx True False\n",
            "at at ADP IN prep xx True True\n",
            "buying buy VERB VBG pcomp xxxx True False\n",
            "U.K. U.K. PROPN NNP compound X.X. False False\n",
            "startup startup NOUN NN dobj xxxx True False\n",
            "for for ADP IN prep xxx True True\n",
            "$ $ SYM $ quantmod $ False False\n",
            "1 1 NUM CD compound d False False\n",
            "billion billion NUM CD pobj xxxx True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dSNcCfOAwi7-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}